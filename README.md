# ğŸ’  Resonance AI Host

### Leverage the power of Large Language Models (LLMs) with your local machine's capabilities.

![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)
![Streamlit](https://img.shields.io/badge/Framework-Streamlit-red?logo=streamlit)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Active-success)

[English](#english) | [ä¸­æ–‡](#chinese)

---

<a name="english"></a>
## ğŸŒ English Introduction

**Resonance** is an advanced **Local AI Host Agent** designed for Windows. It acts as an intelligent operating system layer that connects LLMs (Local or Cloud) with your local machine's capabilities.

Instead of just chatting, Resonance can **see** your files, **run** your scripts, and **evolve** by learning new skills.

### âœ¨ Key Features

*   **ğŸ§  Hybrid Brain**: Seamlessly switch between Local LLMs (Ollama, etc.) for privacy and Cloud LLMs (GPT-4, DeepSeek) for complex reasoning.
*   **âš¡ Skills System**: Register local automation scripts (Python, PowerShell) as "Skills". The Agent can call them intelligently with parameters.
*   **ğŸ“‚ File Awareness**: Scan project directories to understand your workspace and read file contents directly.
*   **ğŸ”‹ System Monitor**: Real-time monitoring of CPU, RAM, and Battery via the dashboard.
*   **ğŸ’¾ Long-term Memory**: Remembers your projects, preferences, and facts across sessions.
*   **ğŸ–¥ï¸ Dual Interface**: Use it via a beautiful Web UI (Streamlit) or a geeky Command Line Interface (CLI).

---

### ğŸ› ï¸ Configuration & Environment Setup

Follow this guide to set up the robust Conda environment and configuration files.

#### 1. Create Conda Environment
Ensure you have Anaconda or Miniconda installed. Open your terminal:

```bash
# Create a fresh environment with Python 3.11
conda create -n resonance python=3.11 -y

# Activate the environment
conda activate resonance

# Install dependencies
pip install -r requirements.txt
```

#### 2. Initialize Configuration
You need to create the configuration file `config/config.yaml`.

Two equivalent ways to create a config:

**Option A: Leverage Quick Start Template**  
Run the following command in the project root to create a default config:

```powershell
# Windows PowerShell
copy config\config.yaml.template config\config.yaml
```

**Option B: Manual Configuration (Template Content)**
If `config.yaml.template` does not exist, create a file named `config/config.yaml` and paste the following content:

```yaml
# config/config.yaml
active_profile: openai_main  # The profile ID to use by default

system:
  name: Resonance
  version: 2.3.0
  log_dir: ./logs
  user_profile_path: config/user_profile.yaml
  system_prompt: "" # Leave empty to use default internal prompt

scripts:
  # Example Skill
  say_hello:
    command: Write-Host "Hello from Resonance!"
    description: Print a greeting message
    cwd: null
    timeout: 30
    delay: 0
```


---

### 3. ğŸš€ Usage Guide

#### 1. Run Web Interface
The main dashboard for monitoring and interaction.
```bash
python main.py
```
*Access via browser (usually http://localhost:8501).*

#### 2. Run CLI Mode(Need a model profile configured)
Quickly execute tasks without opening the UI.
```bash
python main.py "Check my battery status and scan D:\Projects"
```
### 4. Setup Model Profiles

#### It's a must for Resonance to work properly.

**Run the Web Interface, and you will see a side panel, configure your model profiles there.**

If above method fails, please:

Manually edit `config/profiles.yaml` to add your API keys.

```yaml
# config/profiles.yaml
profiles:
  openai_main:
    name: OpenAI GPT-4
    provider: openai
    model: gpt-4
    api_key: sk-YOUR_KEY_HERE
    base_url: https://api.openai.com/v1
    temperature: 0.7
  
  local_ollama:
    name: Local Llama3
    provider: openai
    model: llama3
    api_key: ollama
    base_url: http://localhost:11434/v1
    temperature: 0.7
```

[![Star History Chart](https://api.star-history.com/svg?repos=JulianRyder01/Resonance&type=Date)](https://star-history.com/JulianRyder01/Resonance&Date)

---

<a name="chinese"></a>
## ğŸ‡¨ğŸ‡³ ä¸­æ–‡ä»‹ç»

**Resonance** æ˜¯ä¸€ä¸ªä¸“ä¸º Windows è®¾è®¡çš„é«˜çº§**æœ¬åœ°æ™ºèƒ½ä½“ä¸»æœº (AI Host)**ã€‚å®ƒä¸ä»…ä»…æ˜¯ä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œæ›´æ˜¯ä¸€ä¸ªè¿æ¥å¤§æ¨¡å‹ï¼ˆæœ¬åœ°æˆ–äº‘ç«¯ï¼‰ä¸ä½ ç”µè„‘åº•å±‚èƒ½åŠ›çš„æ™ºèƒ½æ“ä½œç³»ç»Ÿå±‚ã€‚

å®ƒä¸ä»…èƒ½é™ªä½ èŠå¤©ï¼Œè¿˜èƒ½**çœ‹æ‡‚**ä½ çš„æ–‡ä»¶ï¼Œ**æ‰§è¡Œ**ä½ çš„è„šæœ¬ï¼Œå¹¶é€šè¿‡å­¦ä¹ æ–°æŠ€èƒ½ä¸æ–­**è¿›åŒ–**ã€‚

### âœ¨ æ ¸å¿ƒç‰¹æ€§

*   **ğŸ§  æ··åˆå¤§è„‘æ¶æ„**ï¼šæ— ç¼åˆ‡æ¢æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚ Ollamaï¼Œä¿æŠ¤éšç§ï¼‰å’Œäº‘ç«¯æ¨¡å‹ï¼ˆå¦‚ GPT-4, DeepSeekï¼Œå¤„ç†å¤æ‚ä»»åŠ¡ï¼‰ã€‚
*   **âš¡ æŠ€èƒ½ (Skills) ç³»ç»Ÿ**ï¼šå°†ä½ çš„æœ¬åœ°è‡ªåŠ¨åŒ–æµç¨‹è„šæœ¬ï¼ˆPython, PowerShellï¼‰æ³¨å†Œä¸ºâ€œæŠ€èƒ½â€ã€‚Agent å¯ä»¥æ™ºèƒ½è°ƒç”¨å®ƒä»¬å¹¶ä¼ é€’å‚æ•°ã€‚
*   **ğŸ“‚ æ–‡ä»¶æ„ŸçŸ¥èƒ½åŠ›**ï¼šæ”¯æŒæ‰«æé¡¹ç›®ç›®å½•ç»“æ„ï¼Œå¹¶èƒ½ç›´æ¥è¯»å–æ–‡ä»¶å†…å®¹è¿›è¡Œåˆ†æã€‚
*   **ğŸ”‹ ç³»ç»Ÿç›‘æ§**ï¼šé€šè¿‡ä»ªè¡¨ç›˜å®æ—¶ç›‘æ§ CPUã€å†…å­˜å’Œç”µæ± çŠ¶æ€ã€‚
*   **ğŸ’¾ é•¿æ—¶è®°å¿†**ï¼šè·¨ä¼šè¯è®°ä½ä½ çš„é¡¹ç›®è·¯å¾„ã€ä¸ªäººåå¥½å’Œå…³é”®äº‹å®ã€‚
*   **ğŸ–¥ï¸ åŒæ¨¡äº¤äº’**ï¼šæ—¢æœ‰ç¾è§‚çš„ Web UI (Streamlit)ï¼Œä¹Ÿæœ‰æå®¢é£çš„å‘½ä»¤è¡Œæ¥å£ (CLI)ã€‚

### ğŸ› ï¸ ç¯å¢ƒæ­å»ºä¸é…ç½®æŒ‡å—

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤åˆ›å»º Conda ç¯å¢ƒå¹¶åˆå§‹åŒ–é…ç½®ã€‚

#### 1. åˆ›å»º Conda ç¯å¢ƒ
ç¡®ä¿å·²å®‰è£… Anaconda æˆ– Minicondaã€‚åœ¨ç»ˆç«¯æ‰§è¡Œï¼š

```bash
# åˆ›å»º Python 3.11 ç¯å¢ƒ
conda create -n resonance python=3.11 -y

# æ¿€æ´»ç¯å¢ƒ
conda activate resonance

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### 2. åˆå§‹åŒ–é…ç½®æ–‡ä»¶
ä½ éœ€è¦åˆ›å»º `config/config.yaml` æ‰èƒ½è¿è¡Œç¨‹åºã€‚

**ä½¿ç”¨æ¨¡æ¿å‘½ä»¤**
åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œä»¥ä¸‹å‘½ä»¤å¿«é€Ÿå¤åˆ¶æ¨¡æ¿ï¼š

```powershell
# Windows PowerShell
copy config\config.yaml.template config\config.yaml
```

**å¦‚æœä»¥ä¸Šæ–¹æ³•å¤±æ•ˆï¼š**

è¯·æ‰‹åŠ¨æ–°å»º `config/config.yaml` å¹¶å¡«å…¥ä»¥ä¸‹å†…å®¹ï¼š

```yaml
# config/config.yaml
active_profile: openai_main  # é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹é…ç½®ID

system:
  name: Resonance
  version: 2.3.0
  log_dir: ./logs
  user_profile_path: config/user_profile.yaml
  system_prompt: "" # ç•™ç©ºåˆ™ä½¿ç”¨å†…ç½®é»˜è®¤æç¤ºè¯

scripts:
  # ç¤ºä¾‹æŠ€èƒ½
  info_box:
    command: Write-Host "Resonance Online"
    description: æ˜¾ç¤ºç³»ç»Ÿåœ¨çº¿çŠ¶æ€
    cwd: null
    timeout: 60
    delay: 0
```


### 3. ğŸš€ è¿è¡Œ

```bash
# å¯åŠ¨ Web å›¾å½¢ç•Œé¢
python main.py

# æˆ–è€…ä½¿ç”¨å‘½ä»¤è¡Œæ¨¡å¼å¿«é€Ÿæ‰§è¡Œ
python main.py "å¸®æˆ‘çœ‹çœ‹ Dç›˜ æœ‰ä»€ä¹ˆé¡¹ç›®"
```

### 4. é…ç½®æ¨¡å‹å¯†é’¥

#### Resonance å¿…é¡»é…ç½®å¥½LLMæ‰èƒ½ä½¿ç”¨ï¼

è¯·æŒ‰ä¸Šä¸€æ­¥çš„æŒ‡å¼•è¿è¡Œèµ·æ¥ï¼Œä½ ä¼šåœ¨æµè§ˆå™¨ç•Œé¢çœ‹è§Resonance UIã€‚

å·¦ä¾§æ é€‰æ‹©é…ç½®æ¨¡å‹ï¼Œå¯ä»¥åœ¨è¿™é‡Œè¾“å…¥ä½ çš„æ¨¡å‹ä¸å¯†é’¥ã€‚

**å¦‚æœä»¥ä¸Šæ–¹æ³•å¤±æ•ˆï¼š**
ç¼–è¾‘ `config/profiles.yaml` å¡«å…¥ä½ çš„æ¨¡å‹ä¿¡æ¯ï¼š

```yaml
# config/profiles.yaml
profiles:
  openai_main:
    name: OpenAI GPT-4
    provider: openai
    model: gpt-4
    api_key: sk-ä½ çš„å¯†é’¥
    base_url: https://api.openai.com/v1
    temperature: 0.7
  
  local_ollama:
    name: æœ¬åœ° Ollama
    provider: openai
    model: qwen2
    api_key: ollama
    base_url: http://localhost:11434/v1
    temperature: 0.7
```
---

**Resonance** - *Echoing Intelligence Locally.*
